{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, RocCurveDisplay\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import f1_score\n",
    "from datetime import datetime\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checking_status</th>\n",
       "      <th>duration</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>savings_status</th>\n",
       "      <th>employment</th>\n",
       "      <th>installment_commitment</th>\n",
       "      <th>personal_status</th>\n",
       "      <th>other_parties</th>\n",
       "      <th>...</th>\n",
       "      <th>property_magnitude</th>\n",
       "      <th>age</th>\n",
       "      <th>other_payment_plans</th>\n",
       "      <th>housing</th>\n",
       "      <th>existing_credits</th>\n",
       "      <th>job</th>\n",
       "      <th>num_dependents</th>\n",
       "      <th>own_telephone</th>\n",
       "      <th>foreign_worker</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>critical/other existing credit</td>\n",
       "      <td>radio/tv</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>no known savings</td>\n",
       "      <td>&gt;=7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>male single</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>real estate</td>\n",
       "      <td>67.0</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>2.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0&lt;=X&lt;200</td>\n",
       "      <td>48.0</td>\n",
       "      <td>existing paid</td>\n",
       "      <td>radio/tv</td>\n",
       "      <td>5951.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>1&lt;=X&lt;4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female div/dep/mar</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>real estate</td>\n",
       "      <td>22.0</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1.0</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no checking</td>\n",
       "      <td>12.0</td>\n",
       "      <td>critical/other existing credit</td>\n",
       "      <td>education</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>4&lt;=X&lt;7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>male single</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>real estate</td>\n",
       "      <td>49.0</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1.0</td>\n",
       "      <td>unskilled resident</td>\n",
       "      <td>2.0</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>existing paid</td>\n",
       "      <td>furniture/equipment</td>\n",
       "      <td>7882.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>4&lt;=X&lt;7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>male single</td>\n",
       "      <td>guarantor</td>\n",
       "      <td>...</td>\n",
       "      <td>life insurance</td>\n",
       "      <td>45.0</td>\n",
       "      <td>none</td>\n",
       "      <td>for free</td>\n",
       "      <td>1.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>2.0</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>delayed previously</td>\n",
       "      <td>new car</td>\n",
       "      <td>4870.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>1&lt;=X&lt;4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>male single</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>no known property</td>\n",
       "      <td>53.0</td>\n",
       "      <td>none</td>\n",
       "      <td>for free</td>\n",
       "      <td>2.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>2.0</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  checking_status  duration                  credit_history  \\\n",
       "0              <0       6.0  critical/other existing credit   \n",
       "1        0<=X<200      48.0                   existing paid   \n",
       "2     no checking      12.0  critical/other existing credit   \n",
       "3              <0      42.0                   existing paid   \n",
       "4              <0      24.0              delayed previously   \n",
       "\n",
       "               purpose  credit_amount    savings_status employment  \\\n",
       "0             radio/tv         1169.0  no known savings        >=7   \n",
       "1             radio/tv         5951.0              <100     1<=X<4   \n",
       "2            education         2096.0              <100     4<=X<7   \n",
       "3  furniture/equipment         7882.0              <100     4<=X<7   \n",
       "4              new car         4870.0              <100     1<=X<4   \n",
       "\n",
       "   installment_commitment     personal_status other_parties  ...  \\\n",
       "0                     4.0         male single          none  ...   \n",
       "1                     2.0  female div/dep/mar          none  ...   \n",
       "2                     2.0         male single          none  ...   \n",
       "3                     2.0         male single     guarantor  ...   \n",
       "4                     3.0         male single          none  ...   \n",
       "\n",
       "   property_magnitude   age  other_payment_plans   housing existing_credits  \\\n",
       "0         real estate  67.0                 none       own              2.0   \n",
       "1         real estate  22.0                 none       own              1.0   \n",
       "2         real estate  49.0                 none       own              1.0   \n",
       "3      life insurance  45.0                 none  for free              1.0   \n",
       "4   no known property  53.0                 none  for free              2.0   \n",
       "\n",
       "                  job num_dependents  own_telephone foreign_worker class  \n",
       "0             skilled            1.0            yes            yes  good  \n",
       "1             skilled            1.0           none            yes   bad  \n",
       "2  unskilled resident            2.0           none            yes  good  \n",
       "3             skilled            2.0           none            yes  good  \n",
       "4             skilled            2.0           none            yes   bad  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"C:/Users/rodlu/OneDrive/Escritorio/Coding_Dojo/Data_Science/Data sets/credit_customers.csv\"\n",
    "df = pd.read_csv(filename)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una copia del dataframe original\n",
    "df_1 = df.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingenieria de Caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminar la columna 'checking_status'\n",
    "df_1.drop('checking_status', axis=1, inplace=True)\n",
    "# Reemplazar valores inconsistentes en la columna 'credit_history': 'no credits/all paid' por 'no credits'\n",
    "df_1['credit_history'] = df_1['credit_history'].replace('no credits/all paid', 'no credits')\n",
    "df_1['credit_history'] = df_1['credit_history'].replace('all paid', 'no credits')\n",
    "# Reemplazar valores con mwnos de 90 en la columna 'purpose' por 'other'\n",
    "df_1['purpose'] = df_1['purpose'].replace('education', 'other')\n",
    "df_1['purpose'] = df_1['purpose'].replace('repairs', 'other')\n",
    "df_1['purpose'] = df_1['purpose'].replace('domestic appliance', 'other')\n",
    "df_1['purpose'] = df_1['purpose'].replace('retraining', 'other')\n",
    "# Reemplazar valores por > 100 y mantener < 100 y 'no known savings'\n",
    "df_1['savings_status'] = df_1['savings_status'].replace('100<=X<500', '>100')\n",
    "df_1['savings_status'] = df_1['savings_status'].replace('500<=X<1000', '>100')\n",
    "df_1['savings_status'] = df_1['savings_status'].replace('>=1000', '>100')\n",
    "# eliminar la columna 'employment'\n",
    "df_1.drop('employment', axis=1, inplace=True)\n",
    "# Dividir la columna personal_status en dos clumnas: gender y marital_status\n",
    "df_1[['gender', 'marital_status']] = df_1['personal_status'].str.split(' ', n=1, expand=True)\n",
    "# Eliminar la columna 'personal_status'\n",
    "df_1.drop('personal_status', axis=1, inplace=True)\n",
    "# Reemplazar valores en la columna 'marital_status'\n",
    "df_1['marital_status'] = df_1['marital_status'].replace('mar/wid', 'not single')\n",
    "df_1['marital_status'] = df_1['marital_status'].replace('div/sep', 'not single')\n",
    "df_1['marital_status'] = df_1['marital_status'].replace('div/dep/mar', 'not single')\n",
    "# eliminar la columna 'other_parties'\n",
    "df_1.drop('other_parties', axis=1, inplace=True)\n",
    "# eliminar la columna 'other_payment_plans'\n",
    "df_1.drop('other_payment_plans', axis=1, inplace=True)\n",
    "# convertir la columna 'job' en una columna binaria skilled y unskilled\n",
    "df_1['job']=df_1['job'].replace('unemp/unskilled non res', 'unskilled')\n",
    "df_1['job']=df_1['job'].replace('unskilled resident', 'unskilled')\n",
    "df_1['job']=df_1['job'].replace('high qualif/self emp/mgmt', 'skilled')\n",
    "# eliminar la columna 'own_telephone'\n",
    "df_1.drop('own_telephone', axis=1, inplace=True)\n",
    "# eliminar la columna 'foreign_worker'\n",
    "df_1.drop('foreign_worker', axis=1, inplace=True)\n",
    "# convertir la columna objetivo en numerica\n",
    "df_1['class']=df_1['class'].replace('good', 1)\n",
    "df_1['class']=df_1['class'].replace('bad', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>savings_status</th>\n",
       "      <th>installment_commitment</th>\n",
       "      <th>residence_since</th>\n",
       "      <th>property_magnitude</th>\n",
       "      <th>age</th>\n",
       "      <th>housing</th>\n",
       "      <th>existing_credits</th>\n",
       "      <th>job</th>\n",
       "      <th>num_dependents</th>\n",
       "      <th>class</th>\n",
       "      <th>gender</th>\n",
       "      <th>marital_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>critical/other existing credit</td>\n",
       "      <td>radio/tv</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>no known savings</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>real estate</td>\n",
       "      <td>67.0</td>\n",
       "      <td>own</td>\n",
       "      <td>2.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.0</td>\n",
       "      <td>existing paid</td>\n",
       "      <td>radio/tv</td>\n",
       "      <td>5951.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>real estate</td>\n",
       "      <td>22.0</td>\n",
       "      <td>own</td>\n",
       "      <td>1.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>not single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>critical/other existing credit</td>\n",
       "      <td>other</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>real estate</td>\n",
       "      <td>49.0</td>\n",
       "      <td>own</td>\n",
       "      <td>1.0</td>\n",
       "      <td>unskilled</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.0</td>\n",
       "      <td>existing paid</td>\n",
       "      <td>furniture/equipment</td>\n",
       "      <td>7882.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>life insurance</td>\n",
       "      <td>45.0</td>\n",
       "      <td>for free</td>\n",
       "      <td>1.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>delayed previously</td>\n",
       "      <td>new car</td>\n",
       "      <td>4870.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>no known property</td>\n",
       "      <td>53.0</td>\n",
       "      <td>for free</td>\n",
       "      <td>2.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration                  credit_history              purpose  \\\n",
       "0       6.0  critical/other existing credit             radio/tv   \n",
       "1      48.0                   existing paid             radio/tv   \n",
       "2      12.0  critical/other existing credit                other   \n",
       "3      42.0                   existing paid  furniture/equipment   \n",
       "4      24.0              delayed previously              new car   \n",
       "\n",
       "   credit_amount    savings_status  installment_commitment  residence_since  \\\n",
       "0         1169.0  no known savings                     4.0              4.0   \n",
       "1         5951.0              <100                     2.0              2.0   \n",
       "2         2096.0              <100                     2.0              3.0   \n",
       "3         7882.0              <100                     2.0              4.0   \n",
       "4         4870.0              <100                     3.0              4.0   \n",
       "\n",
       "  property_magnitude   age   housing  existing_credits        job  \\\n",
       "0        real estate  67.0       own               2.0    skilled   \n",
       "1        real estate  22.0       own               1.0    skilled   \n",
       "2        real estate  49.0       own               1.0  unskilled   \n",
       "3     life insurance  45.0  for free               1.0    skilled   \n",
       "4  no known property  53.0  for free               2.0    skilled   \n",
       "\n",
       "   num_dependents  class  gender marital_status  \n",
       "0             1.0      1    male         single  \n",
       "1             1.0      0  female     not single  \n",
       "2             2.0      1    male         single  \n",
       "3             2.0      1    male         single  \n",
       "4             2.0      0    male         single  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducción y antecedentes del conjunto de datos:\n",
    "El conjunto de datos contiene 1000 filas y 21 columnas con 13 columnas categóricas, 7 columnas numéricas y una columna objetivo 'Class'. Se realizó un proceso de limpieza de datos y reducción de dimensionalid a través de la Ingenieria de Caracteristicas para facilitar el análisis. El objetivo está desbalanceado y se convirtió a numérico en el preprocesamiento. Algunas columnas categóricas tuvieron valores inconsistentes, mientras que otras tuvieron demasiadas categorías y se agruparon en menos categorías. Las columnas 'Checking_status', 'employment', 'other_parties' y 'own_telephone' se eliminaron porque no eran relevantes para el modelo. Los valores de las columnas que se eliminaron eran inconsistentes y en algunos casos con casi todos los valores iguales.\n",
    "\n",
    "Las columnas 'credit_history', 'purpose', 'savings_status' y 'property_magnitude' se convirtieron en dummy. La columna 'personal_status' se renombró a 'gender' y se convirtió en dummy. La columna 'job' se convirtió en binaria. La columna 'foreign_worker' se eliminó porque no era relevante para el modelo.\n",
    "\n",
    "Este conjunto de datos ofrece una buena oportunidad para analizar las características de los clientes y su relación con la aprobación de créditos, con la posibilidad de construir un modelo predictivo para predecir si un cliente será o no aprobado para un crédito."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelos de Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 missing values in training data\n",
      "0 missing values in testing data\n",
      "\n",
      "\n",
      "All data in X_train_processed are float64\n",
      "All data in X_test_processed are float64\n",
      "\n",
      "\n",
      "shape of data is (750, 33)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.244061</td>\n",
       "      <td>2.684089</td>\n",
       "      <td>-0.845753</td>\n",
       "      <td>-0.765547</td>\n",
       "      <td>0.853000</td>\n",
       "      <td>0.986324</td>\n",
       "      <td>2.291288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.255316</td>\n",
       "      <td>-0.680787</td>\n",
       "      <td>0.931039</td>\n",
       "      <td>-1.669735</td>\n",
       "      <td>-0.838754</td>\n",
       "      <td>0.986324</td>\n",
       "      <td>-0.436436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.733429</td>\n",
       "      <td>-0.745299</td>\n",
       "      <td>0.931039</td>\n",
       "      <td>1.042831</td>\n",
       "      <td>-1.105872</td>\n",
       "      <td>-0.710335</td>\n",
       "      <td>-0.436436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.255316</td>\n",
       "      <td>-0.916502</td>\n",
       "      <td>0.931039</td>\n",
       "      <td>1.042831</td>\n",
       "      <td>1.654357</td>\n",
       "      <td>0.986324</td>\n",
       "      <td>-0.436436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.486243</td>\n",
       "      <td>-0.833913</td>\n",
       "      <td>0.931039</td>\n",
       "      <td>0.138642</td>\n",
       "      <td>-0.215476</td>\n",
       "      <td>0.986324</td>\n",
       "      <td>2.291288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6    7   \\\n",
       "0  1.244061  2.684089 -0.845753 -0.765547  0.853000  0.986324  2.291288  0.0   \n",
       "1  0.255316 -0.680787  0.931039 -1.669735 -0.838754  0.986324 -0.436436  1.0   \n",
       "2 -0.733429 -0.745299  0.931039  1.042831 -1.105872 -0.710335 -0.436436  0.0   \n",
       "3  0.255316 -0.916502  0.931039  1.042831  1.654357  0.986324 -0.436436  0.0   \n",
       "4 -0.486243 -0.833913  0.931039  0.138642 -0.215476  0.986324  2.291288  0.0   \n",
       "\n",
       "    8    9   ...   23   24   25   26   27   28   29   30   31   32  \n",
       "0  1.0  0.0  ...  0.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  \n",
       "1  0.0  0.0  ...  1.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  \n",
       "2  0.0  1.0  ...  0.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  1.0  0.0  \n",
       "3  1.0  0.0  ...  0.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  \n",
       "4  0.0  0.0  ...  0.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  1.0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Formato para ML y train test split\n",
    "X = df_1.drop(columns = 'class')\n",
    "y = df_1['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 123, stratify = y)\n",
    "# Instanciar los selectores de columnas categóricas y numéricas para seleccionar las columnas adecuadas\n",
    "cat_selector = make_column_selector(dtype_include='object')\n",
    "num_selector = make_column_selector(dtype_include='number')\n",
    "# Instanciar el escalador estándar y el codificador one hot\n",
    "scaler = StandardScaler()\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "# Make tuples for preprocessing the categorical and numeric columns\n",
    "num_tuple = (scaler, num_selector)\n",
    "cat_tuple = (ohe, cat_selector)\n",
    "#Instanciación de ColumnTransformer\n",
    "col_transformer = make_column_transformer(num_tuple, cat_tuple, remainder = 'passthrough')\n",
    "#Observen que SOLO ENCAJAREMOS LOS DATOS DE ENTRENAMIENTO\n",
    "col_transformer.fit(X_train)\n",
    "#Ahora podemos transformar los conjuntos de entrenamiento y de prueba.\n",
    "X_train_processed = col_transformer.transform(X_train)\n",
    "X_test_processed = col_transformer.transform(X_test)\n",
    "#Ver las transformaciones en dataframe\n",
    "X_train_df = pd.DataFrame(X_train_processed)\n",
    "X_test_df = pd.DataFrame(X_test_processed)\n",
    "print(np.isnan(X_train_df).sum().sum(), 'missing values in training data')\n",
    "print(np.isnan(X_test_df).sum().sum(), 'missing values in testing data')\n",
    "print('\\n')\n",
    "print('All data in X_train_processed are', X_train_processed.dtype)\n",
    "print('All data in X_test_processed are', X_test_processed.dtype)\n",
    "print('\\n')\n",
    "print('shape of data is', X_train_df.shape)\n",
    "print('\\n')\n",
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[ 35  40]\n",
      " [ 50 125]]\n",
      "Precision:  0.7575757575757576\n",
      "Recall:  0.7142857142857143\n",
      "F1:  0.7352941176470589\n",
      "Accuracy test:  0.64\n",
      "Accuracy train:  1.0\n",
      "ROC AUC:  0.5904761904761905\n"
     ]
    }
   ],
   "source": [
    "# Arbol de decision default y Metricas de clasificacion\n",
    "dt = DecisionTreeClassifier(random_state=123)\n",
    "dt.fit(X_train_df, y_train)\n",
    "y_pred = dt.predict(X_test_df)\n",
    "y_pred_train = dt.predict(X_train_df)\n",
    "# calcular la matriz de confusión\n",
    "confusion_matrix(y_test, y_pred)\n",
    "# calcular la precision\n",
    "precision_score(y_test, y_pred)\n",
    "# calcular el recall\n",
    "recall_score(y_test, y_pred)\n",
    "# calcular el f1\n",
    "f1_score(y_test, y_pred)\n",
    "# calcular el accuracy\n",
    "accuracy_score(y_test, y_pred)\n",
    "# calcular el accuracy en los datos de entrenamiento\n",
    "accuracy_score(y_train, y_pred_train)\n",
    "#  calcular el area bajo la curva ROC\n",
    "roc_auc_score(y_test, y_pred)\n",
    "# imprimir todos los resultados\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))\n",
    "print('Accuracy test: ', accuracy_score(y_test, y_pred))\n",
    "print('Accuracy train: ', accuracy_score(y_train, y_pred_train))\n",
    "print('ROC AUC: ', roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "Best Criterion: gini\n",
      "Best max_depth: 7\n",
      "Best min_samples_split: 7\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 25  50]\n",
      " [ 31 144]]\n",
      "Precision:  0.7422680412371134\n",
      "Recall:  0.8228571428571428\n",
      "F1:  0.7804878048780487\n",
      "Accuracy test:  0.676\n",
      "Accuracy train:  0.828\n",
      "ROC AUC:  0.5780952380952381\n"
     ]
    }
   ],
   "source": [
    "# Buscar los mejores hiperparametros para el arbol de decision\n",
    "# Definir los valores de los hiperparametros a probar\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "min_samples_split = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "# Crear el diccionario con los valores de los hiperparametros\n",
    "hyperparameters = dict(criterion=criterion, max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "# Instanciar el modelo\n",
    "dt = DecisionTreeClassifier(random_state=123)\n",
    "# Instanciar la búsqueda en rejilla\n",
    "gridsearch = GridSearchCV(dt, hyperparameters, cv=5, verbose=1)\n",
    "# Ajustar el modelo\n",
    "best_model = gridsearch.fit(X_train_df, y_train)\n",
    "# Ver los mejores hiperparametros\n",
    "print('Best Criterion:', best_model.best_estimator_.get_params()['criterion'])\n",
    "print('Best max_depth:', best_model.best_estimator_.get_params()['max_depth'])\n",
    "print('Best min_samples_split:', best_model.best_estimator_.get_params()['min_samples_split'])\n",
    "print('\\n')\n",
    "# Predecir con el modelo ajustado\n",
    "y_pred = best_model.predict(X_test_df)\n",
    "y_pred_train = best_model.predict(X_train_df)\n",
    "# calcular la matriz de confusión\n",
    "confusion_matrix(y_test, y_pred)\n",
    "# calcular la precision\n",
    "precision_score(y_test, y_pred)\n",
    "# calcular el recall\n",
    "recall_score(y_test, y_pred)\n",
    "# calcular el f1\n",
    "f1_score(y_test, y_pred)\n",
    "# calcular el accuracy\n",
    "accuracy_score(y_test, y_pred)\n",
    "# calcular el accuracy en los datos de entrenamiento\n",
    "accuracy_score(y_train, y_pred_train)\n",
    "#  calcular el area bajo la curva ROC\n",
    "roc_auc_score(y_test, y_pred)\n",
    "# imprimir todos los resultados\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))\n",
    "print('Accuracy test: ', accuracy_score(y_test, y_pred))\n",
    "print('Accuracy train: ', accuracy_score(y_train, y_pred_train))\n",
    "print('ROC AUC: ', roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[ 32  43]\n",
      " [ 30 145]]\n",
      "Precision:  0.7712765957446809\n",
      "Recall:  0.8285714285714286\n",
      "F1:  0.7988980716253444\n",
      "Accuracy test:  0.708\n",
      "Accuracy train:  0.9893333333333333\n",
      "ROC AUC:  0.6276190476190476\n"
     ]
    }
   ],
   "source": [
    "# Bagging Tree default y Metricas de clasificacion\n",
    "bag = BaggingClassifier(random_state=123)\n",
    "bag.fit(X_train_df, y_train)\n",
    "y_pred = bag.predict(X_test_df)\n",
    "y_pred_train = bag.predict(X_train_df)\n",
    "# calcular la matriz de confusión\n",
    "confusion_matrix(y_test, y_pred)\n",
    "# calcular la precision\n",
    "precision_score(y_test, y_pred)\n",
    "# calcular el recall\n",
    "recall_score(y_test, y_pred)\n",
    "# calcular el f1\n",
    "f1_score(y_test, y_pred)\n",
    "# calcular el accuracy\n",
    "accuracy_score(y_test, y_pred)\n",
    "# calcular el accuracy en los datos de entrenamiento\n",
    "accuracy_score(y_train, y_pred_train)\n",
    "#  calcular el area bajo la curva ROC\n",
    "roc_auc_score(y_test, y_pred)\n",
    "# imprimir todos los resultados\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))\n",
    "print('Accuracy test: ', accuracy_score(y_test, y_pred))\n",
    "print('Accuracy train: ', accuracy_score(y_train, y_pred_train))\n",
    "print('ROC AUC: ', roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 225 candidates, totalling 1125 fits\n",
      "Best n_estimators: 50\n",
      "Best max_samples: 0.4\n",
      "Best max_features: 0.5\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 13  62]\n",
      " [  5 170]]\n",
      "Precision:  0.7327586206896551\n",
      "Recall:  0.9714285714285714\n",
      "F1:  0.8353808353808354\n",
      "Accuracy test:  0.732\n",
      "Accuracy train:  0.9293333333333333\n",
      "ROC AUC:  0.5723809523809524\n"
     ]
    }
   ],
   "source": [
    "# Buscar los mejores hiperparametros para el bagging tree\n",
    "# Definir los valores de los hiperparametros a probar\n",
    "n_estimators = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "max_samples = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "max_features = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "# Crear el diccionario con los valores de los hiperparametros\n",
    "hyperparameters = dict(n_estimators=n_estimators, max_samples=max_samples, max_features=max_features)\n",
    "# Instanciar el modelo\n",
    "bag = BaggingClassifier(random_state=123)\n",
    "# Instanciar la búsqueda en rejilla\n",
    "gridsearch = GridSearchCV(bag, hyperparameters, cv=5, verbose=1)\n",
    "# Ajustar el modelo\n",
    "best_model = gridsearch.fit(X_train_df, y_train)\n",
    "# Ver los mejores hiperparametros\n",
    "print('Best n_estimators:', best_model.best_estimator_.get_params()['n_estimators'])\n",
    "print('Best max_samples:', best_model.best_estimator_.get_params()['max_samples'])\n",
    "print('Best max_features:', best_model.best_estimator_.get_params()['max_features'])\n",
    "print('\\n')\n",
    "# Predecir con el modelo ajustado\n",
    "y_pred = best_model.predict(X_test_df)\n",
    "y_pred_train = best_model.predict(X_train_df)\n",
    "# calcular la matriz de confusión\n",
    "confusion_matrix(y_test, y_pred)\n",
    "# calcular la precision\n",
    "precision_score(y_test, y_pred)\n",
    "# calcular el recall\n",
    "recall_score(y_test, y_pred)\n",
    "# calcular el f1\n",
    "f1_score(y_test, y_pred)\n",
    "# calcular el accuracy\n",
    "accuracy_score(y_test, y_pred)\n",
    "# calcular el accuracy en los datos de entrenamiento\n",
    "accuracy_score(y_train, y_pred_train)\n",
    "#  calcular el area bajo la curva ROC\n",
    "roc_auc_score(y_test, y_pred)\n",
    "# imprimir todos los resultados\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))\n",
    "print('Accuracy test: ', accuracy_score(y_test, y_pred))\n",
    "print('Accuracy train: ', accuracy_score(y_train, y_pred_train))\n",
    "print('ROC AUC: ', roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[ 22  53]\n",
      " [ 15 160]]\n",
      "Precision:  0.7511737089201878\n",
      "Recall:  0.9142857142857143\n",
      "F1:  0.8247422680412371\n",
      "Accuracy test:  0.728\n",
      "Accuracy train:  1.0\n",
      "ROC AUC:  0.6038095238095238\n"
     ]
    }
   ],
   "source": [
    "# Random Forest default y Metricas de clasificacion\n",
    "rf = RandomForestClassifier(random_state=123)\n",
    "rf.fit(X_train_df, y_train)\n",
    "y_pred = rf.predict(X_test_df)\n",
    "y_pred_train = rf.predict(X_train_df)\n",
    "# calcular la matriz de confusión\n",
    "confusion_matrix(y_test, y_pred)\n",
    "# calcular la precision\n",
    "precision_score(y_test, y_pred)\n",
    "# calcular el recall\n",
    "recall_score(y_test, y_pred)\n",
    "# calcular el f1\n",
    "f1_score(y_test, y_pred)\n",
    "# calcular el accuracy\n",
    "accuracy_score(y_test, y_pred)\n",
    "# calcular el accuracy en los datos de entrenamiento\n",
    "accuracy_score(y_train, y_pred_train)\n",
    "#  calcular el area bajo la curva ROC\n",
    "roc_auc_score(y_test, y_pred)\n",
    "# imprimir todos los resultados\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))\n",
    "print('Accuracy test: ', accuracy_score(y_test, y_pred))\n",
    "print('Accuracy train: ', accuracy_score(y_train, y_pred_train))\n",
    "print('ROC AUC: ', roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 405 candidates, totalling 2025 fits\n",
      "Best n_estimators: 20\n",
      "Best max_depth: 10\n",
      "Best max_features: 0.2\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 20  55]\n",
      " [ 15 160]]\n",
      "Precision:  0.7441860465116279\n",
      "Recall:  0.9142857142857143\n",
      "F1:  0.8205128205128205\n",
      "Accuracy test:  0.72\n",
      "Accuracy train:  0.9413333333333334\n",
      "ROC AUC:  0.5904761904761905\n"
     ]
    }
   ],
   "source": [
    "# Buscar los mejores hiperparametros para el random forest\n",
    "# Definir los valores de los hiperparametros a probar\n",
    "n_estimators = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "max_depth = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "max_features = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "# Crear el diccionario con los valores de los hiperparametros\n",
    "hyperparameters = dict(n_estimators=n_estimators, max_depth=max_depth, max_features=max_features)\n",
    "# Instanciar el modelo\n",
    "rf = RandomForestClassifier(random_state=123)\n",
    "# Instanciar la búsqueda en rejilla\n",
    "gridsearch = GridSearchCV(rf, hyperparameters, cv=5, verbose=1)\n",
    "# Ajustar el modelo\n",
    "best_model = gridsearch.fit(X_train_df, y_train)\n",
    "# Ver los mejores hiperparametros\n",
    "print('Best n_estimators:', best_model.best_estimator_.get_params()['n_estimators'])\n",
    "print('Best max_depth:', best_model.best_estimator_.get_params()['max_depth'])\n",
    "print('Best max_features:', best_model.best_estimator_.get_params()['max_features'])\n",
    "print('\\n')\n",
    "# Predecir con el modelo ajustado\n",
    "y_pred = best_model.predict(X_test_df)\n",
    "y_pred_train = best_model.predict(X_train_df)\n",
    "# calcular la matriz de confusión\n",
    "confusion_matrix(y_test, y_pred)\n",
    "# calcular la precision\n",
    "precision_score(y_test, y_pred)\n",
    "# calcular el recall\n",
    "recall_score(y_test, y_pred)\n",
    "# calcular el f1\n",
    "f1_score(y_test, y_pred)\n",
    "# calcular el accuracy\n",
    "accuracy_score(y_test, y_pred)\n",
    "# calcular el accuracy en los datos de entrenamiento\n",
    "accuracy_score(y_train, y_pred_train)\n",
    "#  calcular el area bajo la curva ROC\n",
    "roc_auc_score(y_test, y_pred)\n",
    "# imprimir todos los resultados\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))\n",
    "print('Accuracy test: ', accuracy_score(y_test, y_pred))\n",
    "print('Accuracy train: ', accuracy_score(y_train, y_pred_train))\n",
    "print('ROC AUC: ', roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[ 19  56]\n",
      " [ 17 158]]\n",
      "Precision:  0.7383177570093458\n",
      "Recall:  0.9028571428571428\n",
      "F1:  0.8123393316195372\n",
      "Accuracy test:  0.708\n",
      "Accuracy train:  0.7973333333333333\n",
      "ROC AUC:  0.5780952380952381\n"
     ]
    }
   ],
   "source": [
    "# KNN default y Metricas de clasificacion\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_df, y_train)\n",
    "y_pred = knn.predict(X_test_df)\n",
    "y_pred_train = knn.predict(X_train_df)\n",
    "# calcular la matriz de confusión\n",
    "confusion_matrix(y_test, y_pred)\n",
    "# calcular la precision\n",
    "precision_score(y_test, y_pred)\n",
    "# calcular el recall\n",
    "recall_score(y_test, y_pred)\n",
    "# calcular el f1\n",
    "f1_score(y_test, y_pred)\n",
    "# calcular el accuracy\n",
    "accuracy_score(y_test, y_pred)\n",
    "# calcular el accuracy en los datos de entrenamiento\n",
    "accuracy_score(y_train, y_pred_train)\n",
    "#  calcular el area bajo la curva ROC\n",
    "roc_auc_score(y_test, y_pred)\n",
    "# imprimir todos los resultados\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))\n",
    "print('Accuracy test: ', accuracy_score(y_test, y_pred))\n",
    "print('Accuracy train: ', accuracy_score(y_train, y_pred_train))\n",
    "print('ROC AUC: ', roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Best n_neighbors: 9\n",
      "Best weights: distance\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 15  60]\n",
      " [  9 166]]\n",
      "Precision:  0.7345132743362832\n",
      "Recall:  0.9485714285714286\n",
      "F1:  0.8279301745635911\n",
      "Accuracy test:  0.724\n",
      "Accuracy train:  1.0\n",
      "ROC AUC:  0.5742857142857143\n"
     ]
    }
   ],
   "source": [
    "# Buscar los mejores hiperparametros para el KNN\n",
    "# Definir los valores de los hiperparametros a probar\n",
    "n_neighbors = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "weights = ['uniform', 'distance']\n",
    "# Crear el diccionario con los valores de los hiperparametros\n",
    "hyperparameters = dict(n_neighbors=n_neighbors, weights=weights)\n",
    "# Instanciar el modelo\n",
    "knn = KNeighborsClassifier()\n",
    "# Instanciar la búsqueda en rejilla\n",
    "gridsearch = GridSearchCV(knn, hyperparameters, cv=5, verbose=1)\n",
    "# Ajustar el modelo\n",
    "best_model = gridsearch.fit(X_train_df, y_train)\n",
    "# Ver los mejores hiperparametros\n",
    "print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])\n",
    "print('Best weights:', best_model.best_estimator_.get_params()['weights'])\n",
    "print('\\n')\n",
    "# Predecir con el modelo ajustado\n",
    "y_pred = best_model.predict(X_test_df)\n",
    "y_pred_train = best_model.predict(X_train_df)\n",
    "# calcular la matriz de confusión\n",
    "confusion_matrix(y_test, y_pred)\n",
    "# calcular la precision\n",
    "precision_score(y_test, y_pred)\n",
    "# calcular el recall\n",
    "recall_score(y_test, y_pred)\n",
    "# calcular el f1\n",
    "f1_score(y_test, y_pred)\n",
    "# calcular el accuracy\n",
    "accuracy_score(y_test, y_pred)\n",
    "# calcular el accuracy en los datos de entrenamiento\n",
    "accuracy_score(y_train, y_pred_train)\n",
    "#  calcular el area bajo la curva ROC\n",
    "roc_auc_score(y_test, y_pred)\n",
    "# imprimir todos los resultados\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))\n",
    "print('Accuracy test: ', accuracy_score(y_test, y_pred))\n",
    "print('Accuracy train: ', accuracy_score(y_train, y_pred_train))\n",
    "print('ROC AUC: ', roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[ 25  50]\n",
      " [ 17 158]]\n",
      "Precision:  0.7596153846153846\n",
      "Recall:  0.9028571428571428\n",
      "F1:  0.825065274151436\n",
      "Accuracy test:  0.732\n",
      "Accuracy train:  0.764\n",
      "ROC AUC:  0.618095238095238\n"
     ]
    }
   ],
   "source": [
    "# Regresion Logistica default y Metricas de clasificacion\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_df, y_train)\n",
    "y_pred = lr.predict(X_test_df)\n",
    "y_pred_train = lr.predict(X_train_df)\n",
    "# calcular la matriz de confusión\n",
    "confusion_matrix(y_test, y_pred)\n",
    "# calcular la precision\n",
    "precision_score(y_test, y_pred)\n",
    "# calcular el recall\n",
    "recall_score(y_test, y_pred)\n",
    "# calcular el f1\n",
    "f1_score(y_test, y_pred)\n",
    "# calcular el accuracy\n",
    "accuracy_score(y_test, y_pred)\n",
    "# calcular el accuracy en los datos de entrenamiento\n",
    "accuracy_score(y_train, y_pred_train)\n",
    "#  calcular el area bajo la curva ROC\n",
    "roc_auc_score(y_test, y_pred)\n",
    "# imprimir todos los resultados\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))\n",
    "print('Accuracy test: ', accuracy_score(y_test, y_pred))\n",
    "print('Accuracy train: ', accuracy_score(y_train, y_pred_train))\n",
    "print('ROC AUC: ', roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best Penalty: l2\n",
      "Best C: 1.0\n",
      "Best max_iter: 100\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 25  50]\n",
      " [ 17 158]]\n",
      "Precision:  0.7596153846153846\n",
      "Recall:  0.9028571428571428\n",
      "F1:  0.825065274151436\n",
      "Accuracy test:  0.732\n",
      "Accuracy train:  0.764\n",
      "ROC AUC:  0.618095238095238\n"
     ]
    }
   ],
   "source": [
    "# Buscar los mejores hiperparametros para la Regresion Logistica\n",
    "# Definir los valores de los hiperparametros a probar\n",
    "penalty = ['l2']\n",
    "C = np.logspace(0, 4, 10)\n",
    "max_iter = [100, 500, 1000]\n",
    "# Crear el diccionario con los valores de los hiperparametros\n",
    "hyperparameters = dict(C=C, penalty=penalty, max_iter=max_iter)\n",
    "# Instanciar el modelo\n",
    "lr = LogisticRegression()\n",
    "# Instanciar la búsqueda en rejilla\n",
    "gridsearch = GridSearchCV(lr, hyperparameters, cv=5, verbose=1)\n",
    "# Ajustar el modelo\n",
    "best_model = gridsearch.fit(X_train_df, y_train)\n",
    "# Ver los mejores hiperparametros\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])\n",
    "print('Best max_iter:', best_model.best_estimator_.get_params()['max_iter'])\n",
    "print('\\n')\n",
    "# Predecir con el modelo ajustado\n",
    "y_pred = best_model.predict(X_test_df)\n",
    "y_pred_train = best_model.predict(X_train_df)\n",
    "# calcular la matriz de confusión\n",
    "confusion_matrix(y_test, y_pred)\n",
    "# calcular la precision\n",
    "precision_score(y_test, y_pred)\n",
    "# calcular el recall\n",
    "recall_score(y_test, y_pred)\n",
    "# calcular el f1\n",
    "f1_score(y_test, y_pred)\n",
    "# calcular el accuracy\n",
    "accuracy_score(y_test, y_pred)\n",
    "# calcular el accuracy en los datos de entrenamiento\n",
    "accuracy_score(y_train, y_pred_train)\n",
    "#  calcular el area bajo la curva ROC\n",
    "roc_auc_score(y_test, y_pred)\n",
    "# imprimir todos los resultados\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))\n",
    "print('Accuracy test: ', accuracy_score(y_test, y_pred))\n",
    "print('Accuracy train: ', accuracy_score(y_train, y_pred_train))\n",
    "print('ROC AUC: ', roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelos de Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[ 31  44]\n",
      " [ 22 153]]\n",
      "Precision:  0.7766497461928934\n",
      "Recall:  0.8742857142857143\n",
      "F1:  0.8225806451612904\n",
      "Accuracy test:  0.736\n",
      "Accuracy train:  1.0\n",
      "ROC AUC:  0.6438095238095238\n"
     ]
    }
   ],
   "source": [
    "# XGBoost default y Metricas de clasificacion\n",
    "xgb = xgb.XGBClassifier()\n",
    "xgb.fit(X_train_df, y_train)\n",
    "y_pred = xgb.predict(X_test_df)\n",
    "y_pred_train = xgb.predict(X_train_df)\n",
    "# calcular la matriz de confusión\n",
    "confusion_matrix(y_test, y_pred)\n",
    "# calcular la precision\n",
    "precision_score(y_test, y_pred)\n",
    "# calcular el recall\n",
    "recall_score(y_test, y_pred)\n",
    "# calcular el f1\n",
    "f1_score(y_test, y_pred)\n",
    "# calcular el accuracy\n",
    "accuracy_score(y_test, y_pred)\n",
    "# calcular el accuracy en los datos de entrenamiento\n",
    "accuracy_score(y_train, y_pred_train)\n",
    "#  calcular el area bajo la curva ROC\n",
    "roc_auc_score(y_test, y_pred)\n",
    "# imprimir todos los resultados\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))\n",
    "print('Accuracy test: ', accuracy_score(y_test, y_pred))\n",
    "print('Accuracy train: ', accuracy_score(y_train, y_pred_train))\n",
    "print('ROC AUC: ', roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Best learning_rate: 0.2\n",
      "Best max_depth: 3\n",
      "Best n_estimators: 100\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 25  50]\n",
      " [ 19 156]]\n",
      "Precision:  0.7572815533980582\n",
      "Recall:  0.8914285714285715\n",
      "F1:  0.8188976377952756\n",
      "Accuracy test:  0.724\n",
      "Accuracy train:  0.9173333333333333\n",
      "ROC AUC:  0.6123809523809525\n"
     ]
    }
   ],
   "source": [
    "# Xgboost con GridSearchCV\n",
    "# Definir los valores de los hiperparametros a probar\n",
    "learning_rate = [0.1, 0.2, 0.3]\n",
    "max_depth = [3, 4, 5]\n",
    "n_estimators = [100, 200, 300]\n",
    "# Crear el diccionario con los valores de los hiperparametros\n",
    "hyperparameters = dict(learning_rate=learning_rate, max_depth=max_depth, n_estimators=n_estimators)\n",
    "# Instanciar el modelo\n",
    "xgb_model = XGBClassifier()\n",
    "# Instanciar la búsqueda en rejilla\n",
    "gridsearch = GridSearchCV(xgb_model, hyperparameters, cv=5, verbose=1)\n",
    "# Ajustar el modelo\n",
    "best_model = gridsearch.fit(X_train_df, y_train)\n",
    "# Ver los mejores hiperparametros\n",
    "print('Best learning_rate:', best_model.best_estimator_.get_params()['learning_rate'])\n",
    "print('Best max_depth:', best_model.best_estimator_.get_params()['max_depth'])\n",
    "print('Best n_estimators:', best_model.best_estimator_.get_params()['n_estimators'])\n",
    "print('\\n')\n",
    "# Predecir con el modelo ajustado\n",
    "y_pred = best_model.predict(X_test_df)\n",
    "y_pred_train = best_model.predict(X_train_df)\n",
    "# calcular la matriz de confusión\n",
    "confusion_matrix(y_test, y_pred)\n",
    "# calcular la precision\n",
    "precision_score(y_test, y_pred)\n",
    "# calcular el recall\n",
    "recall_score(y_test, y_pred)\n",
    "# calcular el f1\n",
    "f1_score(y_test, y_pred)\n",
    "# calcular el accuracy\n",
    "accuracy_score(y_test, y_pred)\n",
    "# calcular el accuracy en los datos de entrenamiento\n",
    "accuracy_score(y_train, y_pred_train)\n",
    "#  calcular el area bajo la curva ROC\n",
    "roc_auc_score(y_test, y_pred)\n",
    "# imprimir todos los resultados\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))\n",
    "print('Accuracy test: ', accuracy_score(y_test, y_pred))\n",
    "print('Accuracy train: ', accuracy_score(y_train, y_pred_train))\n",
    "print('ROC AUC: ', roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[ 32  43]\n",
      " [ 21 154]]\n",
      "Precision:  0.7817258883248731\n",
      "Recall:  0.88\n",
      "F1:  0.8279569892473119\n",
      "Accuracy test:  0.744\n",
      "Accuracy train:  1.0\n",
      "ROC AUC:  0.6533333333333333\n"
     ]
    }
   ],
   "source": [
    "# LightGBM default y Metricas de clasificacion\n",
    "lgb = lgb.LGBMClassifier()\n",
    "lgb.fit(X_train_df, y_train)\n",
    "y_pred = lgb.predict(X_test_df)\n",
    "y_pred_train = lgb.predict(X_train_df)\n",
    "# calcular la matriz de confusión\n",
    "confusion_matrix(y_test, y_pred)\n",
    "# calcular la precision\n",
    "precision_score(y_test, y_pred)\n",
    "# calcular el recall\n",
    "recall_score(y_test, y_pred)\n",
    "# calcular el f1\n",
    "f1_score(y_test, y_pred)\n",
    "# calcular el accuracy\n",
    "accuracy_score(y_test, y_pred)\n",
    "# calcular el accuracy en los datos de entrenamiento\n",
    "accuracy_score(y_train, y_pred_train)\n",
    "#  calcular el area bajo la curva ROC\n",
    "roc_auc_score(y_test, y_pred)\n",
    "# imprimir todos los resultados\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))\n",
    "print('Accuracy test: ', accuracy_score(y_test, y_pred))\n",
    "print('Accuracy train: ', accuracy_score(y_train, y_pred_train))\n",
    "print('ROC AUC: ', roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Best learning_rate: 0.1\n",
      "Best max_depth: 3\n",
      "Best n_estimators: 100\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 25  50]\n",
      " [ 19 156]]\n",
      "Precision:  0.7572815533980582\n",
      "Recall:  0.8914285714285715\n",
      "F1:  0.8188976377952756\n",
      "Accuracy test:  0.724\n",
      "Accuracy train:  0.86\n",
      "ROC AUC:  0.6123809523809525\n"
     ]
    }
   ],
   "source": [
    "# LightGBM con GridSearchCV\n",
    "# Definir los valores de los hiperparametros a probar\n",
    "learning_rate = [0.1, 0.2, 0.3]\n",
    "max_depth = [3, 4, 5]\n",
    "n_estimators = [100, 200, 300]\n",
    "# Crear el diccionario con los valores de los hiperparametros\n",
    "hyperparameters = dict(learning_rate=learning_rate, max_depth=max_depth, n_estimators=n_estimators)\n",
    "# Instanciar el modelo\n",
    "lgb_model = LGBMClassifier()\n",
    "# Instanciar la búsqueda en rejilla\n",
    "gridsearch = GridSearchCV(lgb_model, hyperparameters, cv=5, verbose=1)\n",
    "# Ajustar el modelo\n",
    "best_model = gridsearch.fit(X_train_df, y_train)\n",
    "# Ver los mejores hiperparametros\n",
    "print('Best learning_rate:', best_model.best_estimator_.get_params()['learning_rate'])\n",
    "print('Best max_depth:', best_model.best_estimator_.get_params()['max_depth'])\n",
    "print('Best n_estimators:', best_model.best_estimator_.get_params()['n_estimators'])\n",
    "print('\\n')\n",
    "# Predecir con el modelo ajustado\n",
    "y_pred = best_model.predict(X_test_df)\n",
    "y_pred_train = best_model.predict(X_train_df)\n",
    "# calcular la matriz de confusión\n",
    "confusion_matrix(y_test, y_pred)\n",
    "# calcular la precision\n",
    "precision_score(y_test, y_pred)\n",
    "# calcular el recall\n",
    "recall_score(y_test, y_pred)\n",
    "# calcular el f1\n",
    "f1_score(y_test, y_pred)\n",
    "# calcular el accuracy\n",
    "accuracy_score(y_test, y_pred)\n",
    "# calcular el accuracy en los datos de entrenamiento\n",
    "accuracy_score(y_train, y_pred_train)\n",
    "#  calcular el area bajo la curva ROC\n",
    "roc_auc_score(y_test, y_pred)\n",
    "# imprimir todos los resultados\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))\n",
    "print('Accuracy test: ', accuracy_score(y_test, y_pred))\n",
    "print('Accuracy train: ', accuracy_score(y_train, y_pred_train))\n",
    "print('ROC AUC: ', roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[ 21  54]\n",
      " [ 16 159]]\n",
      "Precision:  0.7464788732394366\n",
      "Recall:  0.9085714285714286\n",
      "F1:  0.8195876288659794\n",
      "Accuracy test:  0.72\n",
      "Accuracy train:  0.888\n",
      "ROC AUC:  0.5942857142857143\n"
     ]
    }
   ],
   "source": [
    "# GradientBoostingClassifier default y Metricas de clasificacion\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(X_train_df, y_train)\n",
    "y_pred = gbc.predict(X_test_df)\n",
    "y_pred_train = gbc.predict(X_train_df)\n",
    "# calcular la matriz de confusión\n",
    "confusion_matrix(y_test, y_pred)\n",
    "# calcular la precision\n",
    "precision_score(y_test, y_pred)\n",
    "# calcular el recall\n",
    "recall_score(y_test, y_pred)\n",
    "# calcular el f1\n",
    "f1_score(y_test, y_pred)\n",
    "# calcular el accuracy\n",
    "accuracy_score(y_test, y_pred)\n",
    "# calcular el accuracy en los datos de entrenamiento\n",
    "accuracy_score(y_train, y_pred_train)\n",
    "#  calcular el area bajo la curva ROC\n",
    "roc_auc_score(y_test, y_pred)\n",
    "# imprimir todos los resultados\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))\n",
    "print('Accuracy test: ', accuracy_score(y_test, y_pred))\n",
    "print('Accuracy train: ', accuracy_score(y_train, y_pred_train))\n",
    "print('ROC AUC: ', roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Best learning_rate: 0.1\n",
      "Best max_depth: 3\n",
      "Best n_estimators: 100\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 21  54]\n",
      " [ 16 159]]\n",
      "Precision:  0.7464788732394366\n",
      "Recall:  0.9085714285714286\n",
      "F1:  0.8195876288659794\n",
      "Accuracy test:  0.72\n",
      "Accuracy train:  0.888\n",
      "ROC AUC:  0.5942857142857143\n"
     ]
    }
   ],
   "source": [
    "# GradientBoostingClassifier con GridSearchCV\n",
    "# Definir los valores de los hiperparametros a probar\n",
    "learning_rate = [0.1, 0.2, 0.3]\n",
    "max_depth = [3, 4, 5]\n",
    "n_estimators = [100, 200, 300]\n",
    "# Crear el diccionario con los valores de los hiperparametros\n",
    "hyperparameters = dict(learning_rate=learning_rate, max_depth=max_depth, n_estimators=n_estimators)\n",
    "# Instanciar el modelo\n",
    "gbc_model = GradientBoostingClassifier()\n",
    "# Instanciar la búsqueda en rejilla\n",
    "gridsearch = GridSearchCV(gbc_model, hyperparameters, cv=5, verbose=1)\n",
    "# Ajustar el modelo\n",
    "best_model = gridsearch.fit(X_train_df, y_train)\n",
    "# Ver los mejores hiperparametros\n",
    "print('Best learning_rate:', best_model.best_estimator_.get_params()['learning_rate'])\n",
    "print('Best max_depth:', best_model.best_estimator_.get_params()['max_depth'])\n",
    "print('Best n_estimators:', best_model.best_estimator_.get_params()['n_estimators'])\n",
    "print('\\n')\n",
    "# Predecir con el modelo ajustado\n",
    "y_pred = best_model.predict(X_test_df)\n",
    "y_pred_train = best_model.predict(X_train_df)\n",
    "# calcular la matriz de confusión\n",
    "confusion_matrix(y_test, y_pred)\n",
    "# calcular la precision\n",
    "precision_score(y_test, y_pred)\n",
    "# calcular el recall\n",
    "recall_score(y_test, y_pred)\n",
    "# calcular el f1\n",
    "f1_score(y_test, y_pred)\n",
    "# calcular el accuracy\n",
    "accuracy_score(y_test, y_pred)\n",
    "# calcular el accuracy en los datos de entrenamiento\n",
    "accuracy_score(y_train, y_pred_train)\n",
    "#  calcular el area bajo la curva ROC\n",
    "roc_auc_score(y_test, y_pred)\n",
    "# imprimir todos los resultados\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))\n",
    "print('Accuracy test: ', accuracy_score(y_test, y_pred))\n",
    "print('Accuracy train: ', accuracy_score(y_train, y_pred_train))\n",
    "print('ROC AUC: ', roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arbol de Decision\n",
    "Confusion Matrix: \n",
    " [[ 25  50]\n",
    " [ 31 144]]\n",
    "Precision:  0.7422680412371134\n",
    "Recall:  0.8228571428571428\n",
    "F1:  0.7804878048780487\n",
    "Accuracy test:  0.676\n",
    "Accuracy train:  0.828\n",
    "ROC AUC:  0.5780952380952381\n",
    "\n",
    "Bagging Classifier\n",
    "Confusion Matrix: \n",
    " [[ 13  62]\n",
    " [  5 170]]\n",
    "Precision:  0.7327586206896551\n",
    "Recall:  0.9714285714285714\n",
    "F1:  0.8353808353808354\n",
    "Accuracy test:  0.732\n",
    "Accuracy train:  0.9293333333333333\n",
    "ROC AUC:  0.5723809523809524\n",
    "\n",
    "Random Forest\n",
    "Confusion Matrix: \n",
    " [[ 20  55]\n",
    " [ 15 160]]\n",
    "Precision:  0.7441860465116279\n",
    "Recall:  0.9142857142857143\n",
    "F1:  0.8205128205128205\n",
    "Accuracy test:  0.72\n",
    "Accuracy train:  0.9413333333333334\n",
    "ROC AUC:  0.5904761904761905\n",
    "\n",
    "KNN Classifier\n",
    "Confusion Matrix: \n",
    " [[ 15  60]\n",
    " [  9 166]]\n",
    "Precision:  0.7345132743362832\n",
    "Recall:  0.9485714285714286\n",
    "F1:  0.8279301745635911\n",
    "Accuracy test:  0.724\n",
    "Accuracy train:  1.0\n",
    "ROC AUC:  0.5742857142857143\n",
    "\n",
    "Regresion Logistica\n",
    "Confusion Matrix: \n",
    " [[ 25  50]\n",
    " [ 17 158]]\n",
    "Precision:  0.7596153846153846\n",
    "Recall:  0.9028571428571428\n",
    "F1:  0.825065274151436\n",
    "Accuracy test:  0.732\n",
    "Accuracy train:  0.764\n",
    "ROC AUC:  0.618095238095238\n",
    "\n",
    "XGBoost\n",
    "Confusion Matrix: \n",
    " [[ 25  50]\n",
    " [ 19 156]]\n",
    "Precision:  0.7572815533980582\n",
    "Recall:  0.8914285714285715\n",
    "F1:  0.8188976377952756\n",
    "Accuracy test:  0.724\n",
    "Accuracy train:  0.9173333333333333\n",
    "ROC AUC:  0.6123809523809525\n",
    "\n",
    "LightGBM\n",
    "Confusion Matrix: \n",
    " [[ 25  50]\n",
    " [ 19 156]]\n",
    "Precision:  0.7572815533980582\n",
    "Recall:  0.8914285714285715\n",
    "F1:  0.8188976377952756\n",
    "Accuracy test:  0.724\n",
    "Accuracy train:  0.86\n",
    "ROC AUC:  0.6123809523809525\n",
    "\n",
    "Gradient Boosting\n",
    "Confusion Matrix: \n",
    " [[ 21  54]\n",
    " [ 16 159]]\n",
    "Precision:  0.7464788732394366\n",
    "Recall:  0.9085714285714286\n",
    "F1:  0.8195876288659794\n",
    "Accuracy test:  0.72\n",
    "Accuracy train:  0.888\n",
    "ROC AUC:  0.5942857142857143\n",
    "\n",
    "Para seleccionar el mejor modelo, debemos considerar varias métricas de evaluación. En general, buscamos un equilibrio entre la precisión, el recall, el F1-score y el ROC AUC, y buscamos la mayor precisión posible junto con un buen equilibrio entre recall y F1-score.\n",
    "\n",
    "En este caso, el modelo que muestra el mejor rendimiento general y un equilibrio aceptable entre las métricas es la Regresión Logística. Tiene una precisión de 0.760, un recall de 0.903 y un F1-score de 0.825. Además, el ROC AUC de 0.618 indica un rendimiento razonable para la curva ROC.\n",
    "\n",
    "La Regresión Logística también tiene un buen equilibrio entre el rendimiento en los conjuntos de entrenamiento y prueba, lo que sugiere una capacidad de generalización adecuada. Sin embargo, es importante tener en cuenta que este análisis se basa únicamente en los resultados proporcionados y no considera otros factores, como la complejidad del modelo y los requisitos específicos del problema.\n",
    "\n",
    "En resumen, el modelo elegido para predecir si un cliente es bueno o malo para tomar un crédito es la Regresión Logística"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
